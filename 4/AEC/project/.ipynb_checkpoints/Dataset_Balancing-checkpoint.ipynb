{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, TomekLinks\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, accuracy_score, roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "training = pd.read_csv(\"training.csv\",sep=\";\")\n",
    "test= pd.read_csv(\"test.csv\",sep=\";\")\n",
    "\n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'species'. \n",
    "training[' workclass']= label_encoder.fit_transform(training[' workclass'])\n",
    "training[' education']= label_encoder.fit_transform(training[' education'])\n",
    "training[' marital-status']= label_encoder.fit_transform(training[' marital-status'])\n",
    "training[' occupation']= label_encoder.fit_transform(training[' occupation'])\n",
    "training[' relationship']= label_encoder.fit_transform(training[' relationship'])\n",
    "training[' race']= label_encoder.fit_transform(training[' race'])\n",
    "training[' sex']= label_encoder.fit_transform(training[' sex'])\n",
    "training[' native-country']= label_encoder.fit_transform(training[' native-country'])\n",
    "training[' salary-classification']= label_encoder.fit_transform(training[' salary-classification'])\n",
    "\n",
    "#test\n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'species'. \n",
    "test[' workclass']= label_encoder.fit_transform(test[' workclass'])\n",
    "test[' education']= label_encoder.fit_transform(test[' education'])\n",
    "test[' marital-status']= label_encoder.fit_transform(test[' marital-status'])\n",
    "test[' occupation']= label_encoder.fit_transform(test[' occupation'])\n",
    "test[' relationship']= label_encoder.fit_transform(test[' relationship'])\n",
    "test[' race']= label_encoder.fit_transform(test[' race'])\n",
    "test[' sex']= label_encoder.fit_transform(test[' sex'])\n",
    "test[' native-country']= label_encoder.fit_transform(test[' native-country'])\n",
    "test[' salary-classification']= label_encoder.fit_transform(test[' salary-classification'])\n",
    "\n",
    "\n",
    "\n",
    "data = training[['age', ' workclass', ' fnlwgt', ' education', ' education-num', ' marital-status', ' occupation', \n",
    "             ' relationship', ' race', ' sex', ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country']]\n",
    "target = training[' salary-classification']\n",
    "\n",
    "\n",
    "data_test = test[['age', ' workclass', ' fnlwgt', ' education', ' education-num', ' marital-status', ' occupation', \n",
    "             ' relationship', ' race', ' sex', ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country']]\n",
    "target_test = test[' salary-classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "age              0\n",
       " workclass       0\n",
       " fnlwgt          0\n",
       " education       0\n",
       " education-num   0\n",
       " marital-status  0\n",
       " occupation      0\n",
       " relationship    0\n",
       " race            0\n",
       " sex             0\n",
       " capital-gain    0\n",
       " capital-loss    0\n",
       " hours-per-week  0\n",
       " native-country  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEECAYAAAA72gP/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbeklEQVR4nO3df1SUZf7/8dcAisoPkaO24a/EcsPKOER66ihnNQ23Vq1dFNTFCjPXVhRdXRMX1EClNbFWEsu2U8FxM3+0S7merazkoAkbu2oiVu4x07DU1A0IB2Su7x+d5hOr6OVXZkB4Pv5i7nnfN+9bbuc1133PfY3DGGMEAMBl+DR3AwCAawOBAQCwQmAAAKwQGAAAKwQGAMCKX3M34El79uyRv79/c7cBANcUp9OpyMjIC5a36sDw9/dXREREc7cBANeU8vLyiy7nlBQAwAqBAQCwQmAAAKwQGG3Qli1blJiYqMTERI0fP1633Xab3nnnHY0YMcK9vKSkpME6R48e1aRJkzRx4kTNnTtXNTU1kqT09HSNHz9ef/3rXyVJlZWVmjt3rrd3CYAXOJp6Lqm6ujqlpqbqyy+/VG1traZPn67rr79e06ZN0w033CBJmjBhgu677z7l5OTogw8+kJ+fn1JTUzVw4EAdOXJETzzxhBwOh2666SYtWrRIPj4+F629nPLyci56X8aSJUt08803q6KiQgMGDFBsbOxF62bOnKmRI0dq9OjR2rhxo06ePKkJEyZo4cKFysnJ0UMPPaS8vDw9/fTTGjNmjPr37+/lPQHQVBp77WzyEUZBQYFCQkK0fv16vfjii8rIyFBZWZkeeeQR5eXlKS8vT/fdd5/KyspUUlKijRs3Kjs7W0uWLJEkLV++XCkpKVq/fr2MMdq+fXujtbg6H3/8sQ4dOqT4+HiVlZVp8+bNmjhxorKysnT+/PkGtYcOHVJMTIwkKSoqSqWlpfL391d9fb3q6urUvn17HT16VDU1NYQF0Eo1+cdqR40a5X6XaoyRr6+v9u/fr8OHD2v79u3q06ePUlNTVVpaqiFDhsjhcCgsLEz19fU6ffq0ysrKNGjQIElSTEyMdu7cqb59+160NjQ09JK9OJ3ORj8eBunpp5/W6NGjVV5erhtvvFGDBw/Wddddp9zcXD3zzDO6//773bVhYWHKz8/X8OHDtWXLFn3zzTc6cuSIIiIi9Jvf/EZjxozR8uXLFRcXpzlz5sjHx0eTJk1Shw4dmnEPATSlJg+MgIAASVJVVZVmzpyplJQU1dbWaty4cbr11luVm5ur5557TkFBQQoJCWmwXmVlpYwxcjgcDZZVVVVdtPZygcF9GI379ttvderUKY0fP16S1KNHDwUHB0uS4uLi9I9//KPBv92yZcuUkZGh3bt3KyYmRj169FBERIS75l//+pduu+02nThxQvfee68k6bPPPnNvH8C1w6v3YRw/flyTJ0/W2LFjNXr0aI0cOVK33nqrJGnkyJE6cOCAAgMDVV1d7V6nurpaQUFB8vHxabAsODi40Vr8//vnP/+pu+66S9L3I8ExY8boq6++kiR9+OGHuuWWWxrU79q1S7Nnz1ZeXp58fX119913N3j+5Zdf1iOPPKJz587J19dXDodD3333nXd2BoBXNHlgnDp1SklJSZo3b57i4uIkSVOmTNG+ffsk/d+LUVRUlIqKiuRyuVRRUSGXy6XQ0FANGDBAxcXFkqTCwkJFR0c3WusNzrp6r/webzt8+LB69uwpSXI4HMrMzNSMGTP061//WjU1NRo/frzOnj2rGTNmSJL69u2ruXPnKiEhQYcPH24wcti6dauGDRumDh06aNSoUfrzn/+sV155RT//+c+bZd88rbUeE8DlNPmnpDIzM7Vt2zaFh4e7l6WkpGjFihVq166dunbtqoyMDAUGBmr16tUqLCyUy+XSggULFB0drcOHDystLU11dXUKDw9XZmamfH19L1p7OU31Kak75r161dtA61G6YnJztwB4VGOvnU0eGC0JgQFPIDDQ2nntY7UAgNaJwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABY8WvqDdbV1Sk1NVVffvmlamtrNX36dN1444164okn5HA4dNNNN2nRokXy8fFRTk6OPvjgA/n5+Sk1NVUDBw7UkSNHrGsBAN7T5IFRUFCgkJAQrVixQmfPntUDDzygm2++WSkpKRo8eLDS09O1fft2hYWFqaSkRBs3btTx48eVnJyszZs3a/ny5da1AADvafLAGDVqlGJjYyVJxhj5+vqqrKxMgwYNkiTFxMRo586d6tu3r4YMGSKHw6GwsDDV19fr9OnTV1QbGhp6yV6cTqfKy8uvan8iIiKuan20Tld7XAHXoiYPjICAAElSVVWVZs6cqZSUFD311FNyOBzu5ysrK1VVVaWQkJAG61VWVsoYY117ucDw9/fnBR8ewXGF1qyxN0Qeueh9/PhxTZ48WWPHjtXo0aPl4/N/v6a6ulrBwcEKDAxUdXV1g+VBQUFXVAsA8J4mD4xTp04pKSlJ8+bNU1xcnCRpwIABKi4uliQVFhYqOjpaUVFRKioqksvlUkVFhVwul0JDQ6+oFgDgPU1+Smrt2rX69ttvtWbNGq1Zs0aStHDhQmVmZio7O1vh4eGKjY2Vr6+voqOjFR8fL5fLpfT0dEnS/PnzlZaWZlULAPAehzHGNHcTnlJeXt4k55rvmPdqE3SD1qJ0xeTmbgHwqMZeO7lxDwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGDFY4Gxd+9eJSYmSpIOHDigoUOHKjExUYmJifr73/8uScrJyVFcXJwSEhK0b98+SdKRI0c0YcIETZw4UYsWLZLL5Wq0FgDgPX6e2Oi6detUUFCgjh07SpLKysr0yCOPKCkpyV1TVlamkpISbdy4UcePH1dycrI2b96s5cuXKyUlRYMHD1Z6erq2b9+usLCwi9YCALzHIyOM3r17a/Xq1e7H+/fv1wcffKBJkyYpNTVVVVVVKi0t1ZAhQ+RwOBQWFqb6+nqdPn1aZWVlGjRokCQpJiZGu3btarQWAOA9HhlhxMbG6tixY+7HAwcO1Lhx43TrrbcqNzdXzz33nIKCghQSEuKuCQgIUGVlpYwxcjgcDZZVVVVdtDY0NPSSfTidTpWXl1/VvkRERFzV+midrva4Aq5FHgmM/zVy5EgFBwe7f87IyNA999yj6upqd011dbWCgoLk4+PTYFlwcLACAwMvWns5/v7+vODDIziu0Jo19obIK5+SmjJlivtC9YcffqhbbrlFUVFRKioqksvlUkVFhVwul0JDQzVgwAAVFxdLkgoLCxUdHd1oLQDAe7wywli8eLEyMjLUrl07de3aVRkZGQoMDFR0dLTi4+PlcrmUnp4uSZo/f77S0tKUnZ2t8PBwxcbGytfX96K1AADvcRhjTHM34Snl5eVNcurgjnmvNkE3aC1KV0xu7hYAj2rstZMb9wAAVggMAIAVq8DYuHFjg8evvsopGgBoay550futt97Se++9p+LiYu3evVuSVF9fr88++0yTJ3MeFwDakksGxtChQ9WtWzedPXtW8fHxkiQfHx/16tXLK80BAFqOSwZG586dNXjwYA0ePFjffPONnE6npO9HGQCAtsXqPowlS5Zox44d6t69u3vqjtdee83TvQEAWhCrwNi7d6/efffdBtN2AADaFqsE6NOnj/t0FACgbbIaYRw/flzDhg1Tnz59JIlTUgDQBlkFxsqVKz3dBwCghbMKjDfeeOOCZTNmzGjyZgAALZdVYHTt2lWSZIzRgQMH3N+zDQBoO6wCIyEhocHjRx991CPNAABaLqvAOHz4sPvnkydPqqKiwmMNAQBaJqvA+PEXFvn7+2v+/PkeawgA0DJZBUZeXp7OnDmjo0ePqmfPnnw9KgC0QVY37m3btk0JCQlau3at4uPj9be//c3TfQEAWhirEcbLL7+sLVu2KCAgQFVVVXrooYc0duxYT/cGAGhBrEYYDodDAQEBkqTAwED5+/t7tCkAQMtjNcLo1auXsrKyFB0drdLSUvXu3dvTfQEAWhirEUZ8fLw6d+6sXbt2acuWLZo0aZKn+wIAtDBWgbF8+XLdf//9Sk9P16ZNm5SVleXpvgAALYxVYLRr1859GqpXr158LwYAtEFW1zDCwsKUnZ2tyMhI7du3T927d/d0XwCAFsb6lFRoaKh27Nih0NBQLV++3NN9AQBaGKsRhr+/vx5++GEPtwIAaMm4GAEAsEJgAACsEBgAACsEBgDACoEBALBCYAAArBAYAAArHguMvXv3KjExUZJ05MgRTZgwQRMnTtSiRYvkcrkkSTk5OYqLi1NCQoL27dt3xbUAAO/xSGCsW7dOf/jDH+R0OiV9f6d4SkqK1q9fL2OMtm/frrKyMpWUlGjjxo3Kzs7WkiVLrrgWAOA9HgmM3r17a/Xq1e7HZWVlGjRokCQpJiZGu3btUmlpqYYMGSKHw6GwsDDV19fr9OnTV1QLAPAeq6lBrlRsbKyOHTvmfmyMkcPhkCQFBASosrJSVVVVCgkJcdf8sPxKakNDQy/Zh9PpVHl5+VXtS0RExFWtj9bpao8r4FrkkcD4Xz+eDr26ulrBwcEKDAxUdXV1g+VBQUFXVHs5/v7+vODDIziu0Jo19obIK5+SGjBggIqLiyVJhYWFio6OVlRUlIqKiuRyuVRRUSGXy6XQ0NArqgUAeI9XRhjz589XWlqasrOzFR4ertjYWPn6+io6Olrx8fFyuVxKT0+/4loAgPc4jDGmuZvwlPLy8iY5dXDHvFeboBu0FqUrJjd3C4BHNfbayY17AAArBAYAwAqBAQCwQmAAAKwQGAAAKwQGAMAKgQEAsEJgAGgx6urqNG/ePE2cOFFxcXHavn27+7k333xT8fHxja77469UkL6fKSIuLk4zZ850f03Ck08+2WCeO1wZr9zpDQA2CgoKFBISohUrVujs2bN64IEHdM899+jAgQPatGmTGrvPeN26dSooKFDHjh3dy9avX6+XXnpJf/rTn3Tw4EH5+PgoMDBQPXv29NbutDqMMAC0GKNGjdKsWbMkfT/Lta+vr86cOaPs7GylpqY2ut7/fqWC9P2s1ufOnZPT6VTHjh21bt06TZ061aP9t3YEBoAWIyAgQIGBgaqqqtLMmTM1a9YsLVy4UAsWLFBAQECj68XGxsrPr+EJk8cff1zLly9Xjx499MUXXygqKkpvvfWW0tPT9e9//9vTu9IqERgAWpTjx49r8uTJGjt2rG644QYdOXJEixcv1pw5c3To0CEtXbrUajv9+vXTqlWrNHXqVG3atEm/+MUvVFRUpPT0dK1Zs8bDe9E6cQ0DQItx6tQpJSUlKT09XXfddZckaevWrZKkY8eOac6cOVq4cOEVbXPDhg168MEHJUkul0sOh0M1NTVN23gbwQgDuEaZ887mbqHJrV27Vt9++63WrFmjxMREJSYm6ty5cxet/f3vf6+KiopLbq+qqkolJSUaPny4OnfurG7dumnChAmKi4vzRPstgiePC6Y3t8D05vixljS9+RdP3tbcLaCF6Z3+8VVvg+nNAQBXhcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFb8vPnLHnzwQQUGBkqSevbsqfj4eC1dulS+vr4aMmSIZsyYIZfLpcWLF+uTTz5R+/btlZmZqT59+mjPnj0X1AIAvMdrgeF0OmWMUV5ennvZ2LFjtXr1avXq1UuPPfaYDhw4oGPHjqm2tlYbNmzQnj17lJWVpdzcXC1atOiC2gEDBnirfQBo87wWGAcPHlRNTY2SkpJ0/vx5JScnq7a2Vr1795YkDRkyRLt27dLJkyc1dOhQSVJkZKT279+vqqqqi9YSGADgPV4LjA4dOmjKlCkaN26cPv/8c02dOlXBwcHu5wMCAnT06FFVVVW5T1tJkq+v7wXLfqi9HKfTqfLy8qvqOyIi4qrWR+t0tcdVU+DYRGM8dXx6LTD69u2rPn36yOFwqG/fvgoKCtLZs2fdz1dXVys4OFjnzp1TdXW1e7nL5VJgYGCDZT/UXo6/vz//qeARHFdoya72+GwscLz2KalNmzYpKytLkvT111+rpqZGnTp10hdffCFjjIqKihQdHa2oqCgVFhZKkvbs2aP+/fsrMDBQ7dq1u6AWAOA9XhthxMXFacGCBZowYYIcDoeWLVsmHx8fzZ07V/X19RoyZIhuv/123Xbbbdq5c6cSEhJkjNGyZcskSUuWLLmgFgDgPV4LjPbt22vlypUXLH/99dcbPPbx8dGTTz55QV1kZOQFtQAA7+HGPQCAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYIXAAABYITAAAFYIDACAFQIDAGCFwAAAWCEwAABWCAwAgBUCAwBghcAAAFghMAAAVggMAIAVAgMAYMWvuRu4Ei6XS4sXL9Ynn3yi9u3bKzMzU3369GnutgCgTbimRhjvvvuuamtrtWHDBv3ud79TVlZWc7cEAG3GNRUYpaWlGjp0qCQpMjJS+/fvb+aOAKDtuKZOSVVVVSkwMND92NfXV+fPn5ef38V3w+l0qry8/Kp/b37SnVe9DbQeTXFMNZlxrzd3B2hhmuL4dDqdF11+TQVGYGCgqqur3Y9dLlejYSF9PwoBADSNa+qUVFRUlAoLCyVJe/bsUf/+/Zu5IwBoOxzGGNPcTdj64VNSn376qYwxWrZsmfr169fcbQFAm3BNBQYAoPlcU6ekAADNh8AAAFghMAAAVggMXJLL5VJ6erri4+OVmJioI0eONHdLQAN79+5VYmJic7fRJlxT92HA+348HcuePXuUlZWl3Nzc5m4LkCStW7dOBQUF6tixY3O30iYwwsAlMR0LWrLevXtr9erVzd1Gm0Fg4JIam44FaAliY2MvOdsDmhaBgUu60ulYALReBAYuielYAPyAt4q4pJEjR2rnzp1KSEhwT8cCoG1iahAAgBVOSQEArBAYAAArBAYAwAqBAQCwQmAAAKwQGGizhg8f3uiX3TeF4uJizZ49+6q3c/LkSS1evFiS9M477+jee+/Vq6++qhkzZlzxtjZs2KC6ujqVl5crJyfnqntD28J9GEAL161bN3dgvPfee3riiSc0fPhwTZ48+Yq39fzzz+uBBx5QRESEIiIimrhTtHYEBlqVt99+W+vWrZOfn5+6d++uVatW6cSJE1q8eLGcTqdOnjyplJQUjRgxwr3Op59+qqysLNXX1+vMmTNavHixoqKiNGzYMIWHh6tfv356//33tXHjRoWEhGj9+vWqrq7W1KlT3dswxigjI0P79u1TXV2dkpOTFRQU5H4+Pz9fb7/9tmpqatSlSxfl5OToyy+/1IIFC+Tn5yeXy6WVK1fK399fKSkpMsbI6XRqyZIlCgoK0pw5czRt2jQVFhZq//796tKli2bMmKGdO3dq7969WrZsmVwul6677jo9/fTT2rdvn3JycmSMUXV1tVauXKmPPvpIJ0+e1OzZs/XQQw/ptdde06pVq1RQUKBXXnlF7du31w033KAnn3xSb775pnbs2KFz587piy++0NSpU/XLX/7Sq39LtEAGaEWSk5PNtm3bjDHGvPHGG+a///2v2blzp9m9e7cxxpjS0lLz8MMPG2OMGTZsmDl37pzZunWrOXjwoDHGmIKCArNw4UJjjDE//elPzenTp40xxjz77LMmPz/fGGNMfHy8OXnyZIPf+/bbb5uUlBRjjDFnz541q1atMrt37zYpKSmmvr7erF692tTX1xtjjElKSjIfffSRyc/PN0uXLjW1tbVm165d5pNPPjHvv/++SU5ONjU1Nebjjz82H330kTl69KgZN26cMcaY+fPnmx07dhhjjLn77ruNMcaMGTPGHDp0yBhjzOuvv272799v8vPzzVdffWWMMSY3N9esWbOmwT7/0Nvp06fNiBEjTGVlpTHGmKVLl5q8vDyzefNmk5SUZIwx5vDhwyY2NrYp/jy4xjHCQKuyYMECPf/888rPz1d4eLhGjBihbt26KTc3V5s2bZLD4bhgtt3u3btrzZo16tChg6qrq92z83bp0kVdunSRJP3qV7/SnDlzdOedd6pr167q2rWrpk2bpu+++079+/fXddddp8jISElS586dlZKSouLiYkmSj4+P2rVrpzlz5qhTp0766quvdP78ecXFxWndunV69NFHFRQUpNmzZysmJkaff/65Hn/8cfn5+Wn69OmX3edTp06pX79+kqRx48ZJko4fP66lS5eqU6dO+vrrrxUVFXXRdY8ePaobb7zRvc933nmnioqKdPvtt+vmm2+WJF1//fWqra29kj8DWikueqNV2bBhg5KTk5Wfny/p+4vEzz77rMaOHasVK1Zo8ODBMv8zG87SpUs1c+ZMPfXUU+rfv7/7eR+f//vv0aNHDwUFBWnt2rWKi4uT9P31gLy8PKWlpSk8PFwff/yxJKmyslJTpkxxr3vw4EG9++67euaZZ5SWliaXyyVjjLZv36477rhDr7zyikaNGqUXX3xRxcXF6t69u1566SVNnz5d2dnZl93n7t276/PPP5ckvfDCC3rnnXeUlpamZcuWKSsrS927d3fvk8PhkMvlcq/bs2dP/ec//9F3330nSSopKVHfvn3dtcCPMcJAqzJw4EBNmzZNAQEB6tSpk372s5+pXbt2+uMf/6gXXnhBP/nJT3TmzJkG64wZM0azZs1ScHDwRZ//wfjx45WZmakVK1Zc8Nw999yjDz/8UBMmTFB9fb1++9vfup/r06ePOnbsqISEBEnfX8Q+ceKEIiMjNX/+fOXm5srlcmnBggUKCwvTnDlz9Je//EXnz59vsJ3GLFmyRKmpqfLx8VG3bt308MMPa8yYMZo0aZI6duyorl276sSJE5Kk6OhoPfbYY+7thoaGKjk5WZMnT5aPj4969+6tuXPnauvWrXb/4GhTmHwQsLRt2zZ9+umnmjVrVnO3AjQLRhiAhezsbBUXF2vt2rXN3QrQbBhhAACscNEbAGCFwAAAWCEwAABWCAwAgBUCAwBg5f8BREg0w3U48y0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "ax = sns.countplot(x=' salary-classification',data=training)\n",
    "\n",
    "\n",
    "total = len(training[' salary-classification'])\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:.1f}%'.format(100 * height/total),\n",
    "            ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteSampler(X_train, y_train):\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_balanced, y_train = smote.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underSampler(X_train, y_train):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_balanced, y_train = rus.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroidSampler(X_train, y_train):\n",
    "    cc = ClusterCentroids(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomekSampler(X_train, y_train):\n",
    "    cc = TomekLinks(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of oversampling and undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteeenSampler(X_train, y_train):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_balanced, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das diferentes técnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScaling(X_train):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    return scaled_data;\n",
    "\n",
    "def evaluateTechnique(balancer):\n",
    "    X_train = robustScaling(data)\n",
    "    \n",
    "    X_train, y_train = balancer(data, target)\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(class_weight='balanced'),\n",
    "        LinearRegression(normalize = True),\n",
    "        SVC(class_weight='balanced'),\n",
    "        KMeans(),\n",
    "        KNeighborsClassifier(n_neighbors=29),\n",
    "        GaussianNB(),\n",
    "        \n",
    "        #LinearSVC(max_iter=10000, class_weight='balanced'),\n",
    "        #GaussianProcessClassifier(),\n",
    "        #DecisionTreeClassifier(class_weight='balanced'),\n",
    "        #MLPClassifier(max_iter=10000),\n",
    "        #AdaBoostClassifier(),\n",
    "        #RandomForestClassifier(class_weight='balanced'),\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    names = [\n",
    "             \"Logistic regression\", \"Linear regression\",\n",
    "             \"SMV\", \"KMeans\", \"KNearest Neighbors (29)\"\n",
    "             , \"Gaussian naive bayes\"]\n",
    "\n",
    "\n",
    "    metrics = {'recall0': make_scorer(recall_score, pos_label = 0), \n",
    "               'recall1': make_scorer(recall_score, pos_label = 1),\n",
    "               'precision0': make_scorer(precision_score, pos_label = 0),\n",
    "               'precision1': make_scorer(precision_score, pos_label = 0),\n",
    "               'accuracy' : 'accuracy',\n",
    "               'roc_auc': 'roc_auc'\n",
    "              }\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        scores = cross_validate(clf, X_train, y_train, cv=10, scoring=metrics)\n",
    "        print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (scores['test_accuracy'].mean(), scores['test_roc_auc'].mean(),\n",
    "                scores['test_recall0'].mean(), scores['test_precision0'].mean(),\n",
    "                scores['test_recall1'].mean(), scores['test_precision1'].mean()), name)\n",
    "        \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.666 || AUROC 0.751 || (Accuracy, Precision) 0:( 0.772, 0.639)  1:( 0.559, 0.639) -> Logistic regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-09ff23dad2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluateTechnique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverSampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-fb531b3fa994>\u001b[0m in \u001b[0;36mevaluateTechnique\u001b[1;34m(balancer)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n\u001b[0;32m     45\u001b[0m               % (scores['test_accuracy'].mean(), scores['test_roc_auc'].mean(),\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 score = scorer._score(cached_call, estimator,\n\u001b[0m\u001b[0;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0m\u001b[0;32m    213\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \"\"\"\n\u001b[1;32m-> 1735\u001b[1;33m     _, r, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1736\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1434\u001b[0m                                     pos_label)\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                          str(average_options))\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(overSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.646 || AUROC 0.732 || (Accuracy, Precision) 0:( 0.730, 0.627)  1:( 0.562, 0.627) -> Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.543 || AUROC 0.635 || (Accuracy, Precision) 0:( 0.349, 0.321)  1:( 0.736, 0.321) -> Linear regression\n",
      "Accuracy: 0.731 || AUROC 0.808 || (Accuracy, Precision) 0:( 0.674, 0.761)  1:( 0.788, 0.761) -> SMV\n",
      "Accuracy: 0.591 || AUROC 0.656 || (Accuracy, Precision) 0:( 0.987, 0.551)  1:( 0.194, 0.551) -> KMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.560 || AUROC 0.670 || (Accuracy, Precision) 0:( 0.514, 0.734)  1:( 0.606, 0.734) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.623 || AUROC 0.841 || (Accuracy, Precision) 0:( 0.945, 0.575)  1:( 0.302, 0.575) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(smoteSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.653 || AUROC 0.742 || (Accuracy, Precision) 0:( 0.756, 0.630)  1:( 0.551, 0.630) -> Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.545 || AUROC 0.612 || (Accuracy, Precision) 0:( 0.387, 0.226)  1:( 0.703, 0.226) -> Linear regression\n",
      "Accuracy: 0.614 || AUROC 0.656 || (Accuracy, Precision) 0:( 0.638, 0.609)  1:( 0.590, 0.609) -> SMV\n",
      "Accuracy: 0.586 || AUROC 0.636 || (Accuracy, Precision) 0:( 0.995, 0.547)  1:( 0.177, 0.547) -> KMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.542 || AUROC 0.640 || (Accuracy, Precision) 0:( 0.324, 0.685)  1:( 0.761, 0.685) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.629 || AUROC 0.833 || (Accuracy, Precision) 0:( 0.946, 0.579)  1:( 0.312, 0.579) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(underSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateTechnique(centroidSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluateTechnique(smoteeenSampler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
