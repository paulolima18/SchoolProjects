{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, TomekLinks\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, accuracy_score, roc_auc_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"training.csv\",sep=\";\")\n",
    "test= pd.read_csv(\"test.csv\",sep=\";\")\n",
    "\n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'species'. \n",
    "training[' workclass']= label_encoder.fit_transform(training[' workclass'])\n",
    "training[' education']= label_encoder.fit_transform(training[' education'])\n",
    "training[' marital-status']= label_encoder.fit_transform(training[' marital-status'])\n",
    "training[' occupation']= label_encoder.fit_transform(training[' occupation'])\n",
    "training[' relationship']= label_encoder.fit_transform(training[' relationship'])\n",
    "training[' race']= label_encoder.fit_transform(training[' race'])\n",
    "training[' sex']= label_encoder.fit_transform(training[' sex'])\n",
    "training[' native-country']= label_encoder.fit_transform(training[' native-country'])\n",
    "training[' salary-classification']= label_encoder.fit_transform(training[' salary-classification'])\n",
    "\n",
    "#test\n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'species'. \n",
    "test[' workclass']= label_encoder.fit_transform(test[' workclass'])\n",
    "test[' education']= label_encoder.fit_transform(test[' education'])\n",
    "test[' marital-status']= label_encoder.fit_transform(test[' marital-status'])\n",
    "test[' occupation']= label_encoder.fit_transform(test[' occupation'])\n",
    "test[' relationship']= label_encoder.fit_transform(test[' relationship'])\n",
    "test[' race']= label_encoder.fit_transform(test[' race'])\n",
    "test[' sex']= label_encoder.fit_transform(test[' sex'])\n",
    "test[' native-country']= label_encoder.fit_transform(test[' native-country'])\n",
    "test[' salary-classification']= label_encoder.fit_transform(test[' salary-classification'])\n",
    "\n",
    "\n",
    "\n",
    "data = training[['age', ' workclass', ' fnlwgt', ' education', ' education-num', ' marital-status', ' occupation', \n",
    "             ' relationship', ' race', ' sex', ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country']]\n",
    "target = training[' salary-classification']\n",
    "\n",
    "\n",
    "data_test = test[['age', ' workclass', ' fnlwgt', ' education', ' education-num', ' marital-status', ' occupation', \n",
    "             ' relationship', ' race', ' sex', ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country']]\n",
    "target_test = test[' salary-classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteSampler(X_train, y_train):\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_balanced, y_train = smote.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underSampler(X_train, y_train):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_balanced, y_train = rus.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroidSampler(X_train, y_train):\n",
    "    cc = ClusterCentroids(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomekSampler(X_train, y_train):\n",
    "    cc = TomekLinks(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of oversampling and undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteeenSampler(X_train, y_train):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_balanced, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das diferentes técnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScaling(X_train):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    return scaled_data;\n",
    "\n",
    "def evaluateTechnique(balancer):\n",
    "    X_train = robustScaling(data)\n",
    "    \n",
    "    X_train, y_train = balancer(data, target)\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(class_weight='balanced', max_iter=10000),\n",
    "        SVC(class_weight='balanced'),\n",
    "        KNeighborsClassifier(n_neighbors=2),\n",
    "        GaussianNB(),\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    names = [\n",
    "             \"Logistic regression\",\n",
    "             \"SMV\", \n",
    "             \"KNearest Neighbors (2)\"\n",
    "             , \"Gaussian naive bayes\"]\n",
    "\n",
    "\n",
    "    metrics = {'recall0': make_scorer(recall_score, pos_label = 0), \n",
    "               'recall1': make_scorer(recall_score, pos_label = 1),\n",
    "               'precision0': make_scorer(precision_score, pos_label = 0, zero_division='warn'),\n",
    "               'precision1': make_scorer(precision_score, pos_label = 0, zero_division='warn'),\n",
    "               'accuracy' : 'accuracy',\n",
    "               'roc_auc': 'roc_auc'\n",
    "              }\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        scores = cross_validate(clf, X_train, y_train, cv=10, scoring=metrics)\n",
    "        print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (scores['test_accuracy'].mean(), scores['test_roc_auc'].mean(),\n",
    "                scores['test_recall0'].mean(), scores['test_precision0'].mean(),\n",
    "                scores['test_recall1'].mean(), scores['test_precision1'].mean()), name)\n",
    "        \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.689 || AUROC 0.781 || (Accuracy, Precision) 0:( 0.745, 0.672)  1:( 0.632, 0.672) -> Logistic regression\n",
      "Accuracy: 0.592 || AUROC 0.655 || (Accuracy, Precision) 0:( 0.987, 0.552)  1:( 0.198, 0.552) -> SMV\n",
      "Accuracy: 0.844 || AUROC 0.879 || (Accuracy, Precision) 0:( 0.821, 0.860)  1:( 0.866, 0.860) -> KNearest Neighbors (2)\n",
      "Accuracy: 0.629 || AUROC 0.833 || (Accuracy, Precision) 0:( 0.945, 0.579)  1:( 0.313, 0.579) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(overSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.670 || AUROC 0.766 || (Accuracy, Precision) 0:( 0.724, 0.656)  1:( 0.617, 0.656) -> Logistic regression\n",
      "Accuracy: 0.591 || AUROC 0.671 || (Accuracy, Precision) 0:( 0.987, 0.551)  1:( 0.196, 0.551) -> SMV\n",
      "Accuracy: 0.763 || AUROC 0.809 || (Accuracy, Precision) 0:( 0.830, 0.732)  1:( 0.696, 0.732) -> KNearest Neighbors (2)\n",
      "Accuracy: 0.625 || AUROC 0.840 || (Accuracy, Precision) 0:( 0.945, 0.576)  1:( 0.305, 0.576) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(smoteSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.689 || AUROC 0.763 || (Accuracy, Precision) 0:( 0.781, 0.670)  1:( 0.597, 0.670) -> Logistic regression\n",
      "Accuracy: 0.586 || AUROC 0.642 || (Accuracy, Precision) 0:( 0.997, 0.547)  1:( 0.175, 0.547) -> SMV\n",
      "Accuracy: 0.617 || AUROC 0.640 || (Accuracy, Precision) 0:( 0.796, 0.586)  1:( 0.438, 0.586) -> KNearest Neighbors (2)\n",
      "Accuracy: 0.628 || AUROC 0.830 || (Accuracy, Precision) 0:( 0.944, 0.579)  1:( 0.312, 0.579) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(underSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.642 || AUROC 0.701 || (Accuracy, Precision) 0:( 0.611, 0.649)  1:( 0.673, 0.649) -> Logistic regression\n",
      "Accuracy: 0.583 || AUROC 0.617 || (Accuracy, Precision) 0:( 0.466, 0.609)  1:( 0.700, 0.609) -> SMV\n",
      "Accuracy: 0.537 || AUROC 0.566 || (Accuracy, Precision) 0:( 0.709, 0.528)  1:( 0.365, 0.528) -> KNearest Neighbors (2)\n",
      "Accuracy: 0.598 || AUROC 0.812 || (Accuracy, Precision) 0:( 0.944, 0.558)  1:( 0.252, 0.558) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(centroidSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736 || AUROC 0.860 || (Accuracy, Precision) 0:( 0.800, 0.644)  1:( 0.692, 0.644) -> Logistic regression\n",
      "Accuracy: 0.593 || AUROC 0.735 || (Accuracy, Precision) 0:( 0.995, 0.501)  1:( 0.315, 0.501) -> SMV\n",
      "Accuracy: 0.973 || AUROC 0.982 || (Accuracy, Precision) 0:( 0.977, 0.959)  1:( 0.971, 0.959) -> KNearest Neighbors (2)\n",
      "Accuracy: 0.656 || AUROC 0.911 || (Accuracy, Precision) 0:( 0.955, 0.545)  1:( 0.449, 0.545) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(smoteeenSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.728 || AUROC 0.717 || (Accuracy, Precision) 0:( 0.807, 0.826)  1:( 0.502, 0.826) -> Logistic regression\n",
      "Accuracy: 0.783 || AUROC 0.657 || (Accuracy, Precision) 0:( 0.990, 0.778)  1:( 0.195, 0.778) -> SMV\n",
      "Accuracy: 0.791 || AUROC 0.719 || (Accuracy, Precision) 0:( 0.947, 0.805)  1:( 0.349, 0.805) -> KNearest Neighbors (2)\n",
      "Accuracy: 0.787 || AUROC 0.843 || (Accuracy, Precision) 0:( 0.954, 0.798)  1:( 0.311, 0.798) -> Gaussian naive bayes\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(tomekSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
